import os
import json
from abc import ABC, abstractmethod
from typing import Dict, Any, List, Optional
from langchain_chroma import Chroma
from langchain_core.documents import Document
from langchain_google_genai import GoogleGenerativeAIEmbeddings
import google.generativeai as genai
import pickle


from ..utils.rate_limiter import RateLimiter
from ..utils.tool_detector import ToolDetector
from ..utils.data_tool_manager import DataToolManager


class BaseAgent(ABC):
    """
    Base class cho táº¥t cáº£ AI Agent chuyÃªn biá»‡t
    """
    
    def __init__(self, agent_name: str, data_files: list = None, gemini_model=None, 
                 service_type: str = None, allowed_tools: list = None, user_role: str = "user"):
        self.agent_name = agent_name
        self.data_files = data_files or []
        self.gemini_model = gemini_model
        self.service_type = service_type  # Giá»¯ láº¡i Ä‘á»ƒ backward compatibility
        self.user_role = user_role  # Role cá»§a user (user, staff, admin)
        self.vector_db = None
        self.retriever = None
        self.knowledge_base = []
        self.rate_limiter = RateLimiter()
        self.data_tool_manager = DataToolManager()
        
        # Load permissions trÆ°á»›c
        self._load_permissions()
        
        # Load tools trÆ°á»›c
        self._load_tools()
        
        # Load knowledge base
        self._load_knowledge_base()
        
        # Build vector database
        self._build_vector_db()
    
    def _load_permissions(self):
        """
        Load permissions tá»« file agent_permissions.json
        """
        try:
            permissions_path = os.path.join(os.path.dirname(__file__), "..", "..", "agent_permissions.json")
            if not os.path.exists(permissions_path):
                print(f"âš ï¸ {self.agent_name}: Permissions file not found, using default permissions")
                self.allowed_tools = []
                return
            
            with open(permissions_path, 'r', encoding='utf-8') as f:
                permissions_data = json.load(f)
            
            # Láº¥y permissions cho agent nÃ y
            agent_permissions = permissions_data.get("agents", {}).get(self.agent_name, {})
            self.allowed_tools = agent_permissions.get("allowed_tools", [])
            
            # Láº¥y role permissions
            role_permissions = permissions_data.get("roles", {}).get(self.user_role, {})
            self.role_permissions = role_permissions.get("permissions", [])
            
            print(f"âœ… {self.agent_name}: Loaded permissions for role '{self.user_role}'")
            print(f"âœ… {self.agent_name}: Allowed tools: {self.allowed_tools}")
            
        except Exception as e:
            print(f"ğŸ”¥ {self.agent_name}: Error loading permissions: {e}")
            self.allowed_tools = []
            self.role_permissions = []
    
    def _load_tools(self):
        """
        Load tools tá»« file tools_customer.json (chá»‰ tools dÃ nh cho customer)
        """
        try:
            tools_path = os.path.join(os.path.dirname(__file__), "..", "..", "tools_customer.json")
            if not os.path.exists(tools_path):
                tools_path = os.path.join(os.path.dirname(__file__), "..", "..", "tools.json")
            # Láº¥y tools Ä‘Ã£ lá»c tá»« DataToolManager (cache theo role/allowed_tools)
            filtered_tools = self.data_tool_manager.get_filtered_tools(
                tools_path,
                self.user_role,
                self.allowed_tools,
                getattr(self, 'role_permissions', None)
            )
            print(f"âœ… {self.agent_name}: Filtered {len(filtered_tools)} tools for role '{self.user_role}' from {len(filtered_tools)} total tools")
            self.tool_detector = ToolDetector.get_instance(filtered_tools)
            print(f"âœ… {self.agent_name}: Loaded {len(filtered_tools)} tools from {os.path.basename(tools_path)}")
        except Exception as e:
            print(f"ğŸ”¥ {self.agent_name}: Error loading tools: {e}")
            self.tool_detector = None
    
    def _load_knowledge_base(self):
        """
        Load knowledge base tá»« cÃ¡c file data JSON
        """
        try:
            self.knowledge_base = []
            # LuÃ´n láº¥y data_dir lÃ  thÆ° má»¥c data á»Ÿ project root
            project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..", ".."))
            data_dir = os.path.join(project_root, "data")
            if not os.path.exists(data_dir):
                print(f"ğŸ”¥ {self.agent_name}: Could not find data directory at {data_dir}")
                return
            for data_file in self.data_files:
                clean_data_file = data_file.replace("../", "").replace("../../", "")
                abs_data_path = os.path.join(data_dir, clean_data_file)
                if os.path.exists(abs_data_path):
                    data = self.data_tool_manager.load_data(clean_data_file, [data_dir])
                    for item in data:
                        item['_source_file'] = data_file
                    self.knowledge_base.extend(data)
                    print(f"âœ… {self.agent_name}: Loaded data from {data_file}")
                else:
                    print(f"âš ï¸ {self.agent_name}: Data file {data_file} not found at {abs_data_path}")
            if self.knowledge_base:
                print(f"âœ… {self.agent_name}: Loaded {len(self.knowledge_base)} items from data files")
            else:
                print(f"âš ï¸ {self.agent_name}: No data files loaded")
        except Exception as e:
            print(f"ğŸ”¥ {self.agent_name}: Error loading knowledge base: {e}")
    
    def _build_vector_db(self):
        """
        XÃ¢y dá»±ng hoáº·c load vector database tá»« knowledge base, sá»­ dá»¥ng batch embedding
        """
        try:
            if not self.knowledge_base:
                return
            # ÄÆ°á»ng dáº«n cache vector DB
            project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..", ".."))
            cache_dir = os.path.join(project_root, "data", "vector_db_cache")
            os.makedirs(cache_dir, exist_ok=True)
            cache_file = os.path.join(cache_dir, f"{self.agent_name}_vector_db.pkl")
            # Náº¿u Ä‘Ã£ cÃ³ file cache, load láº¡i
            if os.path.exists(cache_file):
                with open(cache_file, 'rb') as f:
                    self.vector_db = pickle.load(f)
                self.retriever = self.vector_db.as_retriever(search_kwargs={"k": 3})
                print(f"âœ… {self.agent_name}: Loaded vector DB from cache {cache_file}")
                return
            # Náº¿u chÆ°a cÃ³, build má»›i vá»›i batch embedding
            documents = []
            texts = []
            for item in self.knowledge_base:
                content = self._format_knowledge_item(item)
                metadata = {"source": self.agent_name, "type": item.get("type", "general")}
                documents.append(Document(page_content=content, metadata=metadata))
                texts.append(content)
            if documents:
                embeddings = self.data_tool_manager.get_embeddings_batch(texts)
                from langchain_chroma import Chroma
                self.vector_db = Chroma.from_embeddings(texts, embeddings, metadatas=[doc.metadata for doc in documents])
                self.retriever = self.vector_db.as_retriever(search_kwargs={"k": 3})
                # LÆ°u láº¡i vector DB vÃ o cache
                with open(cache_file, 'wb') as f:
                    pickle.dump(self.vector_db, f)
                print(f"âœ… {self.agent_name}: Vector DB built (batch) and cached with {len(documents)} documents at {cache_file}")
        except Exception as e:
            print(f"ğŸ”¥ {self.agent_name}: Error building/loading vector DB: {e}")
    
    def _format_knowledge_item(self, item: Dict[str, Any]) -> str:
        """
        Format knowledge item thÃ nh text (cÃ³ thá»ƒ override trong subclass)
        """
        if isinstance(item, dict):
            return json.dumps(item, ensure_ascii=False)
        return str(item)
    
    def _get_relevant_context(self, user_input: str) -> str:
        """
        Láº¥y context liÃªn quan tá»« vector database
        """
        if not self.retriever:
            return "KhÃ´ng cÃ³ thÃ´ng tin bá»• sung."
        
        try:
            relevant_docs = self.retriever.invoke(user_input)
            context = "\n".join([doc.page_content for doc in relevant_docs])
            return context if context else "KhÃ´ng cÃ³ thÃ´ng tin bá»• sung."
        except Exception as e:
            print(f"âš ï¸ {self.agent_name}: Error retrieving context: {e}")
            return "KhÃ´ng cÃ³ thÃ´ng tin bá»• sung."
    
    def _call_gemini(self, prompt: str, chat_session: Optional[Any] = None) -> str:
        """
        Gá»i Gemini API, cÃ³ thá»ƒ sá»­ dá»¥ng chat_session Ä‘á»ƒ duy trÃ¬ ngá»¯ cáº£nh
        """
        if not self.gemini_model:
            return "Xin lá»—i, AI service hiá»‡n khÃ´ng kháº£ dá»¥ng."
        
        # Apply rate limiting
        self.rate_limiter.wait_if_needed()
        
        try:
            if chat_session:
                # Náº¿u cÃ³ chat_session, gá»­i message vÃ o session
                response = chat_session.send_message(prompt)
            else:
                # Náº¿u khÃ´ng, táº¡o má»™t phiÃªn Ä‘á»™c láº­p
                response = self.gemini_model.generate_content(prompt)
            return response.text
        except Exception as e:
            print(f"ğŸ”¥ {self.agent_name}: Error calling Gemini: {e}")
            return "Xin lá»—i, cÃ³ lá»—i xáº£y ra khi xá»­ lÃ½ yÃªu cáº§u."
    
    def _vector_db_cache_file(self):
        project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..", ".."))
        cache_dir = os.path.join(project_root, "data", "vector_db_cache")
        os.makedirs(cache_dir, exist_ok=True)
        return os.path.join(cache_dir, f"{self.agent_name}_vector_db.pkl")

    def refresh_knowledge(self):
        """
        Refresh knowledge base tá»« file vÃ  xÃ³a cache vector DB náº¿u cÃ³
        """
        # XÃ³a cache vector DB náº¿u tá»“n táº¡i
        cache_file = self._vector_db_cache_file()
        if os.path.exists(cache_file):
            try:
                os.remove(cache_file)
                print(f"ğŸ—‘ï¸ {self.agent_name}: Removed vector DB cache {cache_file}")
            except Exception as e:
                print(f"âš ï¸ {self.agent_name}: Failed to remove vector DB cache: {e}")
        self._load_knowledge_base()
    
    @abstractmethod
    def get_system_prompt(self) -> str:
        """
        Tráº£ vá» system prompt cho agent nÃ y
        """
        pass
    
    @abstractmethod
    def process_request(self, user_input: str, session_id: str = "default", chat_session: Optional[Any] = None) -> Dict[str, Any]:
        """
        Xá»­ lÃ½ yÃªu cáº§u cá»§a user
        """
        pass
    
    def create_response(self, action: str, parameters: Dict[str, Any], 
                       natural_response: str) -> Dict[str, Any]:
        """
        Táº¡o response chuáº©n vá»›i xá»­ lÃ½ actions tá»« Java services
        """
        # Clean parameters to avoid null values
        cleaned_parameters = {}
        for key, value in parameters.items():
            if value is not None and value != "null" and value != "":
                cleaned_parameters[key] = value
        
        # Check if this is a Java service action that needs special handling
        java_service_actions = [
            "add_menu", "delete_menu", "update_menu", "add_item_to_order", "remove_item_from_order",
            "complete_order", "calculate_bill", "get_revenue", "add_table", "delete_table", 
            "update_table", "search_tables", "show_available_tables", "show_all_tables", "create_booking", "cancel_booking", "complete_booking",
            "update_booking", "delete_booking", "create_customer", "update_customer", "delete_customer",
            "get_customer_info", "customer_search", "show_menu", "fix_data"
        ]
        
        if action in java_service_actions:
            # Láº¥y service type tá»« tool definition
            service_type = self._get_service_type_from_action(action)
            if service_type:
                # Add metadata to indicate this should be handled by Java service
                return {
                    "action": action,
                    "parameters": cleaned_parameters,
                    "naturalResponse": natural_response,
                    "agent": self.agent_name,
                    "requiresJavaService": True,
                    "javaServiceType": service_type
                }
        
        return {
            "action": action,
            "parameters": cleaned_parameters,
            "naturalResponse": natural_response,
            "agent": self.agent_name
        }
    
    def _get_service_type_from_action(self, action: str) -> str:
        """
        Láº¥y service type tá»« tool definition thay vÃ¬ hardcode mapping
        """
        if not self.tool_detector:
            return None
        
        for tool in self.tool_detector.tools:
            if tool.get("name") == action:
                return tool.get("service")
        
        return None
    
    def _parse_json_response(self, response_text: str, fallback_action: str = "clarify", 
                           fallback_response: str = "Xin lá»—i, cÃ³ lá»—i xáº£y ra. Vui lÃ²ng thá»­ láº¡i.") -> Dict[str, Any]:
        """
        Parse JSON response from Gemini with improved error handling
        """
        try:
            # First, try to parse as-is
            parsed = json.loads(response_text)
            
            # Clean up null values to prevent JsonNull errors
            if isinstance(parsed, dict):
                # Clean parameters
                if "parameters" in parsed and isinstance(parsed["parameters"], dict):
                    cleaned_params = {}
                    for key, value in parsed["parameters"].items():
                        if value is not None and value != "null" and value != "":
                            cleaned_params[key] = value
                    parsed["parameters"] = cleaned_params
                
                # Ensure required fields exist
                if "action" not in parsed:
                    parsed["action"] = fallback_action
                if "naturalResponse" not in parsed:
                    parsed["naturalResponse"] = fallback_response
                if "parameters" not in parsed:
                    parsed["parameters"] = {}
            
            return parsed
        except json.JSONDecodeError:
            # Try to extract JSON from the response using regex
            import re
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                try:
                    parsed = json.loads(json_match.group())
                    # Clean up null values
                    if isinstance(parsed, dict):
                        if "parameters" in parsed and isinstance(parsed["parameters"], dict):
                            cleaned_params = {}
                            for key, value in parsed["parameters"].items():
                                if value is not None and value != "null" and value != "":
                                    cleaned_params[key] = value
                            parsed["parameters"] = cleaned_params
                    return parsed
                except json.JSONDecodeError:
                    pass
            
            # If all parsing attempts fail, return fallback
            print(f"âš ï¸ {self.agent_name}: Failed to parse JSON response: {response_text[:100]}...")
            return {
                "action": fallback_action,
                "parameters": {},
                "naturalResponse": fallback_response
            }
    
    def detect_tool_from_prompt(self, user_input: str) -> Optional[Dict[str, Any]]:
        """
        Detect if user_input matches any tool using semantic similarity
        Chá»‰ xá»­ lÃ½ tools Ä‘Æ°á»£c phÃ©p sá»­ dá»¥ng (permission-based)
        """
        if not self.tool_detector:
            return None
        
        # Lá»c tools theo agent allowed_tools vÃ  role permissions
        available_tools = []
        for tool in self.tool_detector.tools:
            # Kiá»ƒm tra agent allowed_tools
            if self.allowed_tools and tool.get("name") not in self.allowed_tools:
                continue
            
            # Kiá»ƒm tra role permissions tá»« agent_permissions.json
            if hasattr(self, 'role_permissions') and self.role_permissions:
                if tool.get("name") not in self.role_permissions:
                    continue
            
            available_tools.append(tool)
        
        print(f"ğŸ” {self.agent_name}: Checking {len(available_tools)} tools for role '{self.user_role}'")
        if self.allowed_tools:
            print(f"ğŸ” {self.agent_name}: Allowed tools: {self.allowed_tools}")
        if hasattr(self, 'role_permissions') and self.role_permissions:
            print(f"ğŸ” {self.agent_name}: Role permissions: {self.role_permissions}")
        
        # Táº¡o temporary tool detector vá»›i filtered tools
        temp_detector = ToolDetector(available_tools)
        
        return temp_detector.detect_tool_from_prompt(user_input) 