import google.generativeai as genai
import json
import os
import re
from datetime import datetime, timedelta
from typing import Dict, Any, List
from collections import defaultdict

from flask import Flask, request, jsonify
from flask_cors import CORS

from langchain_chroma import Chroma
from langchain_core.documents import Document
from langchain_google_genai import GoogleGenerativeAIEmbeddings

# --- Step 1: Setup and Configuration ---

# Load environment variables from .env if available
try:
    from dotenv import load_dotenv
    load_dotenv()
    print("‚úÖ .env file loaded.")
except ImportError:
    print("‚ö†Ô∏è Warning: python-dotenv not installed. .env file will not be loaded.")

app = Flask(__name__)
CORS(app)

# Session management for conversation history
session_data = defaultdict(dict)
conversation_history = defaultdict(list)

# Configure Gemini API once at startup
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
gemini_model = None
if GOOGLE_API_KEY:
    try:
        genai.configure(api_key=GOOGLE_API_KEY)
        gemini_model = genai.GenerativeModel('gemini-2.5-flash')
        print("‚úÖ Gemini API configured successfully.")
    except Exception as e:
        print(f"üî• Error configuring Gemini API: {e}")
        gemini_model = None
else:
    print("‚ö†Ô∏è GOOGLE_API_KEY not found. Running in Fallback Mode.")

# --- Step 2: Knowledge Base Setup (The "R" in RAG) ---
# We use ChromaDB for a simple, file-based vector store.
# In a real app, this data would come from a database.
try:
    
    
    # Global variables for knowledge base
    vector_db = None
    retriever = None
    
    # Path to data files
    DATA_DIR = "../data"
    
    def load_knowledge_from_files():
        """ƒê·ªçc t·∫•t c·∫£ file JSON v√† x√¢y d·ª±ng l·∫°i VectorDB t·ª´ ƒë·∫ßu."""
        global vector_db, retriever
        print("üîÑ Starting to load/reload knowledge from files...")
        
        try:
            all_docs = []
            
            # Load menu items
            menu_file = os.path.join(DATA_DIR, 'menu_items.json')
            if os.path.exists(menu_file):
                with open(menu_file, 'r', encoding='utf-8') as f:
                    menu_data = json.load(f)
                
                for item in menu_data:
                    content = f"M√≥n {item['name']}: {item['description']}. Gi√°: {item['price']} VND."
                    all_docs.append(Document(page_content=content, metadata={"source": "menu", "itemId": item['itemId']}))
                print(f"üìã Loaded {len(menu_data)} menu items")
            
            # Load tables
            tables_file = os.path.join(DATA_DIR, 'tables.json')
            if os.path.exists(tables_file):
                with open(tables_file, 'r', encoding='utf-8') as f:
                    tables_data = json.load(f)
                
                for table in tables_data:
                    content = f"B√†n s·ªë {table['tableId']} cho {table['capacity']} ng∆∞·ªùi. Tr·∫°ng th√°i hi·ªán t·∫°i: {table['status']}."
                    all_docs.append(Document(page_content=content, metadata={"source": "table_status", "tableId": table['tableId']}))
                print(f"ü™ë Loaded {len(tables_data)} tables")
            
            # Load bookings
            bookings_file = os.path.join(DATA_DIR, 'bookings.json')
            if os.path.exists(bookings_file):
                with open(bookings_file, 'r', encoding='utf-8') as f:
                    bookings_data = json.load(f)
                
                for booking in bookings_data:
                    content = f"ƒê·∫∑t b√†n s·ªë {booking['bookingId']} cho {booking['numberOfGuests']} ng∆∞·ªùi v√†o {booking['bookingTime']}. Tr·∫°ng th√°i: {booking['status']}."
                    all_docs.append(Document(page_content=content, metadata={"source": "booking", "bookingId": booking['bookingId']}))
                print(f"üìÖ Loaded {len(bookings_data)} bookings")
            
            # Load customers
            customers_file = os.path.join(DATA_DIR, 'customers.json')
            if os.path.exists(customers_file):
                with open(customers_file, 'r', encoding='utf-8') as f:
                    customers_data = json.load(f)
                
                for customer in customers_data:
                    content = f"Kh√°ch h√†ng {customer['name']} (ID: {customer['customerId']}) - SƒêT: {customer['phone']}, Email: {customer['email']}."
                    all_docs.append(Document(page_content=content, metadata={"source": "customer", "customerId": customer['customerId']}))
                print(f"üë• Loaded {len(customers_data)} customers")
            
            # Add static restaurant information
            static_docs = [
                Document(page_content="Gi·ªù m·ªü c·ª≠a c·ªßa nh√† h√†ng l√† t·ª´ 9 gi·ªù s√°ng ƒë·∫øn 10 gi·ªù t·ªëi (22:00) h√†ng ng√†y.", metadata={"source": "info"}),
                Document(page_content="ƒê·ªÉ h·ªßy ƒë·∫∑t b√†n, kh√°ch h√†ng c·∫ßn cung c·∫•p m√£ ƒë·∫∑t b√†n (bookingId).", metadata={"source": "policy"}),
                Document(page_content="Nh√† h√†ng c√≥ c√°c lo·∫°i b√†n d√†nh cho 2 ng∆∞·ªùi, 4 ng∆∞·ªùi, 6 ng∆∞·ªùi v√† 8 ng∆∞·ªùi.", metadata={"source": "info"}),
            ]
            all_docs.extend(static_docs)
            
            if all_docs:
                embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
                vector_db = Chroma.from_documents(all_docs, embeddings)
                retriever = vector_db.as_retriever(search_kwargs={"k": 3})  # Retrieve top 3 relevant docs
                print(f"‚úÖ Knowledge base has been successfully (re)built with {len(all_docs)} documents.")
                return True
            else:
                print("‚ö†Ô∏è No documents found to build knowledge base.")
                return False
                
        except Exception as e:
            print(f"üî• Failed to build knowledge base: {e}")
            return False

    # Initial load of knowledge base
    if load_knowledge_from_files():
        print("‚úÖ ChromaDB knowledge base created from files.")
    else:
        print("‚ö†Ô∏è Failed to create knowledge base from files. Using fallback mode.")
        retriever = None

except ImportError:
    print("‚ö†Ô∏è LangChain or ChromaDB not installed. Retrieval functionality will be disabled.")
    retriever = None
except Exception as e:
    print(f"üî• Error creating ChromaDB knowledge base: {e}")
    retriever = None

# --- Step 3: LLM Interaction with Improved Prompt ---

def get_current_vietnam_time() -> str:
    """Returns the current date and time in Vietnam."""
    # Simulating for the example date
    return "Ch·ªß Nh·∫≠t, ng√†y 29 th√°ng 06 nƒÉm 2025, l√∫c 10:37 s√°ng."


def call_gemini_with_rag(user_input: str, session_id: str = "default", role: str = "USER") -> Dict[str, Any]:
    """
    Calls the Gemini API with a dynamically retrieved context and conversation history.
    """
    if not gemini_model:
        raise ConnectionError("Gemini API not configured.")

    # 1. Retrieve relevant context
    context = "Kh√¥ng c√≥ th√¥ng tin b·ªï sung."
    if retriever:
        relevant_docs = retriever.invoke(user_input)
        context = "\n".join([doc.page_content for doc in relevant_docs])

    # 2. Get conversation history for this session
    history = conversation_history.get(session_id, [])
    history_text = ""
    if history:
        history_text = "\n\nL·ªäCH S·ª¨ H·ªòI THO·∫†I:\n" + "\n".join(history[-5:])  # Last 5 exchanges

    # 3. Create a powerful few-shot prompt with conversation history
    prompt = f"""
    B·∫°n l√† m·ªôt tr·ª£ l√Ω AI th√¥ng minh c·ªßa m·ªôt nh√† h√†ng Vi·ªát Nam.
    Nhi·ªám v·ª• c·ªßa b·∫°n l√† ph√¢n t√≠ch y√™u c·∫ßu c·ªßa kh√°ch h√†ng v√† tr·∫£ v·ªÅ m·ªôt chu·ªói JSON duy nh·∫•t.
    Kh√¥ng th√™m b·∫•t k·ª≥ gi·∫£i th√≠ch hay l·ªùi ch√†o n√†o kh√°c. Ch·ªâ tr·∫£ v·ªÅ JSON.
    QUAN TR·ªåNG: Kh√¥ng escape Unicode characters trong JSON response.

    Th·ªùi gian hi·ªán t·∫°i l√†: {get_current_vietnam_time()}
    Role hi·ªán t·∫°i: {role}

    D∆∞·ªõi ƒë√¢y l√† m·ªôt s·ªë th√¥ng tin c√≥ th·ªÉ h·ªØu √≠ch t·ª´ c∆° s·ªü tri th·ª©c c·ªßa nh√† h√†ng:
    --- CONTEXT ---
    {context}
    --- END CONTEXT ---

    {history_text}

    H√£y tu√¢n th·ªß nghi√™m ng·∫∑t ƒë·ªãnh d·∫°ng JSON sau v·ªõi c√°c tr∆∞·ªùng: "action", "parameters", v√† "naturalResponse".

    C√ÅC ACTION C√ì S·∫¥N:
    1. "show_menu" - Hi·ªÉn th·ªã menu nh√† h√†ng
    2. "show_tables" - Hi·ªÉn th·ªã tr·∫°ng th√°i c√°c b√†n
    3. "show_bookings" - Hi·ªÉn th·ªã danh s√°ch ƒë·∫∑t b√†n
    4. "book_table" - ƒê·∫∑t b√†n (khi ƒë√£ c√≥ ƒë·ªß th√¥ng tin)
    5. "collect_customer_info" - Thu th·∫≠p th√¥ng tin kh√°ch h√†ng tr∆∞·ªõc khi ƒë·∫∑t b√†n
    6. "order_food" - ƒê·∫∑t m√≥n ƒÉn
    7. "calculate_bill" - T√≠nh bill cho b√†n hi·ªán t·∫°i
    8. "cancel_booking" - H·ªßy ƒë·∫∑t b√†n
    9. "clarify" - Y√™u c·∫ßu l√†m r√µ th√™m

    C√ÅC ACTION CH·ªà D√ÄNH CHO MANAGER:
    10. "add_menu" - Th√™m m√≥n ƒÉn m·ªõi v√†o menu
    11. "delete_menu" - X√≥a m√≥n ƒÉn kh·ªèi menu
    12. "add_table" - Th√™m b√†n m·ªõi
    13. "delete_booking" - X√≥a ƒë·∫∑t b√†n
    14. "fix_data" - S·ª≠a l·ªói d·ªØ li·ªáu
    15. "show_customers" - Hi·ªÉn th·ªã danh s√°ch kh√°ch h√†ng
    16. "customer_info" - Xem th√¥ng tin kh√°ch h√†ng
    17. "customer_search" - T√¨m ki·∫øm kh√°ch h√†ng

    L∆ØU √ù QUAN TR·ªåNG V·ªÄ ROLE:
    - USER: Ch·ªâ c√≥ th·ªÉ th·ª±c hi·ªán c√°c action t·ª´ 1-8 (xem th√¥ng tin, ƒë·∫∑t b√†n, g·ªçi m√≥n, h·ªßy ƒë·∫∑t b√†n)
    - MANAGER: C√≥ th·ªÉ th·ª±c hi·ªán t·∫•t c·∫£ c√°c action t·ª´ 1-17 (bao g·ªìm c·∫£ qu·∫£n l√Ω CRUD)
    - N·∫øu USER y√™u c·∫ßu th·ª±c hi·ªán action ch·ªâ d√†nh cho MANAGER, tr·∫£ v·ªÅ action "clarify" v·ªõi th√¥ng b√°o ph√π h·ª£p

    L∆ØU √ù QUAN TR·ªåNG V·ªÄ CONVERSATION HISTORY:
    - N·∫øu kh√°ch h√†ng ƒë√£ cung c·∫•p th√¥ng tin trong l·ªãch s·ª≠ h·ªôi tho·∫°i, s·ª≠ d·ª•ng th√¥ng tin ƒë√≥
    - Kh√¥ng h·ªèi l·∫°i th√¥ng tin ƒë√£ c√≥
    - K·∫øt h·ª£p th√¥ng tin t·ª´ c√°c tin nh·∫Øn tr∆∞·ªõc ƒë·ªÉ hi·ªÉu y√™u c·∫ßu ƒë·∫ßy ƒë·ªß
    - N·∫øu ƒë√£ c√≥ ƒë·ªß th√¥ng tin (t√™n, s·ªë ƒëi·ªán tho·∫°i, s·ªë ng∆∞·ªùi, th·ªùi gian), ti·∫øn h√†nh ƒë·∫∑t b√†n

    V√≠ d·ª• 1: Y√™u c·∫ßu xem menu (USER/MANAGER)
    Kh√°ch h√†ng: "cho t√¥i xem menu"
    JSON:
    {{
        "action": "show_menu",
        "parameters": {{}},
        "naturalResponse": "D·∫° v√¢ng, ƒë√¢y l√† menu c·ªßa nh√† h√†ng ·∫°."
    }}

    V√≠ d·ª• 2: ƒê·∫∑t b√†n v·ªõi th√¥ng tin ƒë·∫ßy ƒë·ªß (USER/MANAGER)
    Kh√°ch h√†ng: "ƒë·∫∑t b√†n 3 ng∆∞·ªùi 7h t·ªëi, t√™n t√¥i l√† Nguy·ªÖn VƒÉn A, s·ªë ƒëi·ªán tho·∫°i 0901234567"
    JSON:
    {{
        "action": "book_table",
        "parameters": {{
            "guests": 3,
            "time": "2025-06-29T19:00:00",
            "customerName": "Nguy·ªÖn VƒÉn A",
            "customerPhone": "0901234567"
        }},
        "naturalResponse": "D·∫° v√¢ng, em ƒë√£ ghi nh·∫≠n th√¥ng tin c·ªßa anh Nguy·ªÖn VƒÉn A. Em s·∫Ω ti·∫øn h√†nh ƒë·∫∑t b√†n cho 3 ng∆∞·ªùi v√†o 7 gi·ªù t·ªëi nay ·∫°."
    }}

    V√≠ d·ª• 3: Cung c·∫•p th√¥ng tin b·ªï sung (USER/MANAGER)
    Kh√°ch h√†ng: "t√™n t√¥i l√† Tr·∫ßn Th·ªã B, s·ªë ƒëi·ªán tho·∫°i 0987654321"
    JSON:
    {{
        "action": "collect_customer_info",
        "parameters": {{
            "customerName": "Tr·∫ßn Th·ªã B",
            "customerPhone": "0987654321"
        }},
        "naturalResponse": "D·∫° v√¢ng, em ƒë√£ ghi nh·∫≠n th√¥ng tin c·ªßa ch·ªã Tr·∫ßn Th·ªã B. Em c·∫ßn th√™m th√¥ng tin v·ªÅ s·ªë ng∆∞·ªùi v√† th·ªùi gian ƒë·∫∑t b√†n ·∫°."
    }}

    V√≠ d·ª• 4: T√≠nh bill (USER/MANAGER)
    Kh√°ch h√†ng: "t√≠nh bill" ho·∫∑c "t√≠nh ti·ªÅn"
    JSON:
    {{
        "action": "calculate_bill",
        "parameters": {{}},
        "naturalResponse": "D·∫° v√¢ng, em s·∫Ω t√≠nh bill cho b√†n hi·ªán t·∫°i c·ªßa anh/ch·ªã ·∫°."
    }}

    V√≠ d·ª• 5: Th√™m m√≥n ƒÉn m·ªõi (CH·ªà MANAGER)
    Kh√°ch h√†ng: "th√™m m√≥n ph·ªü b√≤ gi√° 45000 v√†o menu"
    JSON:
    {{
        "action": "add_menu",
        "parameters": {{
            "name": "Ph·ªü B√≤",
            "price": 45000,
            "description": "M√≥n ph·ªü truy·ªÅn th·ªëng Vi·ªát Nam"
        }},
        "naturalResponse": "D·∫° v√¢ng, em s·∫Ω th√™m m√≥n Ph·ªü B√≤ v·ªõi gi√° 45,000 VND v√†o menu ·∫°."
    }}

    V√≠ d·ª• 6: X√≥a m√≥n ƒÉn (CH·ªà MANAGER)
    Kh√°ch h√†ng: "x√≥a m√≥n s·ªë 3 kh·ªèi menu"
    JSON:
    {{
        "action": "delete_menu",
        "parameters": {{
            "itemId": 3
        }},
        "naturalResponse": "D·∫° v√¢ng, em s·∫Ω x√≥a m√≥n ƒÉn s·ªë 3 kh·ªèi menu ·∫°."
    }}

    V√≠ d·ª• 7: Th√™m b√†n m·ªõi (CH·ªà MANAGER)
    Kh√°ch h√†ng: "th√™m b√†n m·ªõi cho 6 ng∆∞·ªùi"
    JSON:
    {{
        "action": "add_table",
        "parameters": {{
            "capacity": 6
        }},
        "naturalResponse": "D·∫° v√¢ng, em s·∫Ω th√™m b√†n m·ªõi cho 6 ng∆∞·ªùi ·∫°."
    }}

    V√≠ d·ª• 8: X√≥a ƒë·∫∑t b√†n (CH·ªà MANAGER)
    Kh√°ch h√†ng: "x√≥a ƒë·∫∑t b√†n s·ªë 5"
    JSON:
    {{
        "action": "delete_booking",
        "parameters": {{
            "bookingId": 5
        }},
        "naturalResponse": "D·∫° v√¢ng, em s·∫Ω x√≥a ƒë·∫∑t b√†n s·ªë 5 ·∫°."
    }}

    V√≠ d·ª• 9: S·ª≠a l·ªói d·ªØ li·ªáu (CH·ªà MANAGER)
    Kh√°ch h√†ng: "s·ª≠a l·ªói d·ªØ li·ªáu"
    JSON:
    {{
        "action": "fix_data",
        "parameters": {{}},
        "naturalResponse": "D·∫° v√¢ng, em s·∫Ω ki·ªÉm tra v√† s·ª≠a c√°c l·ªói d·ªØ li·ªáu ·∫°."
    }}

    V√≠ d·ª• 10: Xem danh s√°ch kh√°ch h√†ng (CH·ªà MANAGER)
    Kh√°ch h√†ng: "cho t√¥i xem danh s√°ch kh√°ch h√†ng"
    JSON:
    {{
        "action": "show_customers",
        "parameters": {{}},
        "naturalResponse": "D·∫° v√¢ng, em s·∫Ω hi·ªÉn th·ªã danh s√°ch kh√°ch h√†ng ·∫°."
    }}

    V√≠ d·ª• 11: T√¨m ki·∫øm kh√°ch h√†ng (CH·ªà MANAGER)
    Kh√°ch h√†ng: "t√¨m kh√°ch h√†ng t√™n Nguy·ªÖn"
    JSON:
    {{
        "action": "customer_search",
        "parameters": {{
            "searchTerm": "Nguy·ªÖn"
        }},
        "naturalResponse": "D·∫° v√¢ng, em s·∫Ω t√¨m ki·∫øm kh√°ch h√†ng c√≥ t√™n Nguy·ªÖn ·∫°."
    }}

    V√≠ d·ª• 12: USER y√™u c·∫ßu th·ª±c hi·ªán l·ªánh MANAGER
    Kh√°ch h√†ng: "th√™m m√≥n m·ªõi v√†o menu"
    JSON:
    {{
        "action": "clarify",
        "parameters": {{}},
        "naturalResponse": "Xin l·ªói, ch·ª©c nƒÉng n√†y ch·ªâ d√†nh cho qu·∫£n l√Ω. B·∫°n c√≥ th·ªÉ li√™n h·ªá qu·∫£n l√Ω ƒë·ªÉ th·ª±c hi·ªán thao t√°c n√†y ·∫°."
    }}

    L∆ØU √ù QUAN TR·ªåNG:
    - Khi kh√°ch h√†ng y√™u c·∫ßu xem th√¥ng tin (menu, b√†n, ƒë·∫∑t b√†n), s·ª≠ d·ª•ng action t∆∞∆°ng ·ª©ng
    - Khi kh√°ch h√†ng mu·ªën ƒë·∫∑t b√†n nh∆∞ng ch∆∞a cung c·∫•p ƒë·ªß th√¥ng tin, s·ª≠ d·ª•ng action "collect_customer_info"
    - Khi kh√°ch h√†ng ƒë√£ cung c·∫•p ƒë·ªß th√¥ng tin, s·ª≠ d·ª•ng action "book_table"
    - Khi kh√°ch h√†ng mu·ªën ƒë·∫∑t m√≥n, s·ª≠ d·ª•ng action "order_food"
    - Khi kh√°ch h√†ng mu·ªën t√≠nh bill, s·ª≠ d·ª•ng action "calculate_bill"
    - Khi kh√°ch h√†ng mu·ªën h·ªßy ƒë·∫∑t b√†n, s·ª≠ d·ª•ng action "cancel_booking" v·ªõi parameters g·ªìm "bookingId" l√† ID ƒë·∫∑t b√†n (v√≠ d·ª•: "123"). 
    - Khi kh√¥ng hi·ªÉu r√µ y√™u c·∫ßu, s·ª≠ d·ª•ng action "clarify"
    - LU√îN KI·ªÇM TRA ROLE TR∆Ø·ªöC KHI TH·ª∞C HI·ªÜN ACTION QU·∫¢N L√ù
    - LU√îN KI·ªÇM TRA L·ªäCH S·ª¨ H·ªòI THO·∫†I TR∆Ø·ªöC KHI H·ªéI L·∫†I TH√îNG TIN
    - Khi kh√°ch h√†ng g·ªçi m√≥n (order_food) m√† ch∆∞a x√°c ƒë·ªãnh b√†n, h√£y h·ªèi r√µ: "B·∫°n mu·ªën order cho b√†n s·ªë m·∫•y?".
    - N·∫øu kh√°ch h√†ng c√≥ nhi·ªÅu b√†n ƒëang ƒë·∫∑t, h√£y li·ªát k√™ c√°c b√†n ƒë√≥ ƒë·ªÉ kh√°ch h√†ng ch·ªçn.

    B√¢y gi·ªù, h√£y x·ª≠ l√Ω y√™u c·∫ßu th·ª±c t·∫ø c·ªßa kh√°ch h√†ng.

    Kh√°ch h√†ng: "{user_input}"
    JSON:
    """

    try:
        # Th√™m timeout cho Gemini API call
        import time
        start_time = time.time()
        
        response = gemini_model.generate_content(prompt)
        
        # Ki·ªÉm tra th·ªùi gian th·ª±c thi
        elapsed_time = time.time() - start_time
        print(f"‚è±Ô∏è Gemini API call took {elapsed_time:.2f} seconds")
        
        # Clean up the response to extract only the JSON part
        json_match = re.search(r'```json\s*([\s\S]*?)\s*```', response.text)
        if json_match:
            json_str = json_match.group(1)
            return json.loads(json_str)
        else:
            # Fallback if LLM doesn't return the expected format
            return json.loads(response.text.strip())
    except Exception as e:
        print(f"üî• Error during Gemini API call or JSON parsing: {e}")
        raise

def detect_back_to_menu(user_input: str) -> dict:
    """
    Nh·∫≠n di·ªán c√°c l·ªánh quay v·ªÅ menu t·ª´ user input.
    N·∫øu ph√°t hi·ªán, tr·∫£ v·ªÅ action show_menu.
    """
    menu_keywords = [
        "menu", "quay l·∫°i menu", "tr·ªü v·ªÅ menu", "back to menu", "main menu", "v·ªÅ menu", "quay l·∫°i", "tr·ªü v·ªÅ"
    ]
    normalized = user_input.strip().lower()
    for kw in menu_keywords:
        if kw in normalized:
            return {
                "action": "show_menu",
                "parameters": {},
                "naturalResponse": "D·∫° v√¢ng, ƒë√¢y l√† menu c·ªßa nh√† h√†ng ·∫°."
            }
    return None

# --- Step 4: Flask API Routes ---

@app.route('/process', methods=['POST'])
def process_user_input():
    """Main API endpoint to process user input."""
    try:
        data = request.get_json()
        if not data or 'userInput' not in data:
            return jsonify({"error": "Invalid input. 'userInput' field is required."}), 400

        user_input = data['userInput']
        session_id = data.get('sessionId', 'default')  # Get session ID from request
        role = data.get('role', 'USER')  # Get role from request, default to USER
        
        print(f"‚û°Ô∏è Received input from session {session_id} (Role: {role}): {user_input}")

        # ∆Øu ti√™n ki·ªÉm tra l·ªánh quay v·ªÅ menu
        menu_result = detect_back_to_menu(user_input)
        if menu_result:
            return jsonify(menu_result)

        # Add user input to conversation history
        conversation_history[session_id].append(f"Kh√°ch h√†ng: {user_input}")

        # Always try to use the intelligent RAG-based approach first
        if gemini_model:
            try:
                response_data = call_gemini_with_rag(user_input, session_id, role)
                
                # Add AI response to conversation history
                if 'naturalResponse' in response_data:
                    conversation_history[session_id].append(f"AI: {response_data['naturalResponse']}")
                
                # Keep only last 10 exchanges to avoid memory issues
                if len(conversation_history[session_id]) > 10:
                    conversation_history[session_id] = conversation_history[session_id][-10:]
                
                print(f"‚úÖ Gemini RAG response for session {session_id} (Role: {role}): {response_data}")
                return jsonify(response_data)
            except Exception as e:
                print(f"‚ö†Ô∏è RAG call failed for session {session_id}: {e}. No fallback available for this complex task.")
                return jsonify({
                    "action": "clarify",
                    "parameters": {},
                    "naturalResponse": "Xin l·ªói, h·ªá th·ªëng AI ƒëang g·∫∑p s·ª± c·ªë nh·ªè. B·∫°n c√≥ th·ªÉ th·ª≠ l·∫°i sau gi√¢y l√°t ƒë∆∞·ª£c kh√¥ng ·∫°?"
                }), 500
        else:
            # Simple fallback if Gemini is not configured at all
            print("‚ö†Ô∏è Using basic fallback mode as Gemini is not configured.")
            return jsonify({
                "action": "clarify",
                "parameters": {},
                "naturalResponse": "Xin l·ªói, ch·∫ø ƒë·ªô AI th√¥ng minh hi·ªán kh√¥ng kh·∫£ d·ª•ng. Vui l√≤ng th·ª≠ l·∫°i sau."
            })

    except Exception as e:
        print(f"üî• Critical error in /process endpoint: {e}")
        return jsonify({"error": "An internal server error occurred."}), 500

@app.route('/refresh-knowledge', methods=['POST'])
def refresh_knowledge():
    """Endpoint ƒë·ªÉ Java th√¥ng b√°o r·∫±ng d·ªØ li·ªáu ƒë√£ thay ƒë·ªïi."""
    try:
        if load_knowledge_from_files():
            return jsonify({"status": "success", "message": "Knowledge base refreshed."}), 200
        else:
            return jsonify({"status": "error", "message": "Failed to refresh knowledge base."}), 500
    except Exception as e:
        print(f"üî• Error in refresh-knowledge endpoint: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500

@app.route('/health', methods=['GET'])
def health_check():
    """Health check endpoint."""
    return jsonify({
        "status": "healthy",
        "message": "AI Agent is running",
        "gemini_api_status": "available" if gemini_model else "not_configured",
        "knowledge_base_status": "loaded" if retriever else "not_available"
    })

if __name__ == '__main__':
    print("üöÄ Starting AI Restaurant Assistant Server...")
    print("‚è±Ô∏è Timeout settings: 30 seconds for API calls")
    app.run(host='0.0.0.0', port=5000, debug=True, threaded=True)
